---
title: "ISLR"
output: html_notebook
autor: Ren√© Brinkhuis
---

# EXERCISE 8:
```{r}
require(ISLR)
data(Auto)
write.csv(Auto, 'data/auto.csv') # for use with Python
```

## 8a
```{r}
fit.lm <- lm(mpg ~ horsepower, data=Auto)
summary(fit.lm)
```

> [i] Yes, there is a relationship between predictor and response (since the F-statistic `599.7` is far larger than 1)  

> [ii] There is relationship is strong between predictor ans response (since the p-value `< 2.2e-16` is close to 0)  

> [iii] The relationship is negative (since the coefficient `-0.157845` is negative)  

> [iv] See below.  

```{r}
hp98 <- data.frame(horsepower = 98)
predict(fit.lm, hp98)  # predicted mpg
```

```{r}
predict(fit.lm, hp98, interval = "confidence")  # conf interval
```

```{r}
predict(fit.lm, hp98, interval = "prediction")  # pred interval
```

## 8b
```{r}
plot(Auto$horsepower, Auto$mpg)
abline(fit.lm, col="red")
```

## 8c
```{r}
par(mfrow=c(2,2))
plot(fit.lm)
```

# EXERCISE 9:

## 9a
```{r}
require(ISLR)
data(Auto)
pairs(Auto)
```

## 9b
```{r}
cor(subset(Auto, select=-name))
```

## 9c
```{r}
fit.lm <- lm(mpg~.-name, data=Auto)
summary(fit.lm)
```

## 9d
```{r}
par(mfrow=c(2,2))
plot(fit.lm)
```


```{r}
# try 3 predictor transformations
fit.lm4 <- lm(mpg~poly(displacement,3)+weight+year+origin, data=Auto)
fit.lm5 <- lm(mpg~displacement+I(log(weight))+year+origin, data=Auto)
fit.lm6 <- lm(mpg~displacement+I(weight^2)+year+origin, data=Auto)
summary(fit.lm4)
summary(fit.lm5)
summary(fit.lm6)
```
```


# EXERCISE 10:

```{r}
require(ISLR)
data(Carseats)
fit.lm_10a <- lm(Sales ~ Price + Urban + US, data=Carseats)
summary(fit.lm_10a)
```
```


## 10a
```{r}
require(ISLR)
data(Carseats)
fit.lm_10a <- lm(Sales ~ Price + Urban + US, data=Carseats)
summary(fit.lm_10a)
```

## 10e
```{r}
fit.lm_10e <- lm(Sales ~ Price + US, data=Carseats)
summary(fit.lm_10e)
```

## 10g
```{r}
confint(fit.lm_10e)
```

# EXERCISE 11:

## 11a
```{r}
set.seed(1)
x <- rnorm(100)
y <- 2*x + rnorm(100)
```

```{r}
# write data for use with Python
write.csv(data.frame(x, y), "data/ch03_ex11.csv", row.names=FALSE)
```

```{r}
model_a <- lm(y ~ x + 0)
summary(model_a)
```

## 11b
```{r}
model_b <- lm(x ~ y + 0)
summary(model_b)
```

# EXERCISE 13:

## 13a
```{r}
x <- rnorm(100, mean=0, sd=1)
```

## 13b
```{r}
eps <- rnorm(100, mean=0, sd=0.25)
```

## 13c
```{r}
y <- -1 + 0.5*x + eps
```

## 13d
```{r}
plot(x, y)
```

## 13e
```{r}
model_e <- lm(y ~ x)
summary(model_e)
```

## 13f
```{r}
plot(x, y)
abline(-1, 0.5, col="blue", lwd=2)
abline(model_e, col="red", lwd=2)
legend(-3, 0.5, legend=c("population", "fitted model"),  col=c("blue","red"), lwd=2)
```

## 13g
```{r}
model_g <- lm(y ~ x + I(x^2))
summary(model_g)
anova(model_e, model_g)
```

## 13h
```{r}
x <- rnorm(100, mean=0, sd=1)
eps <- rnorm(100, mean=0, sd=0.1)
y <- -1 + 0.5*x + eps
model_h <- lm(y ~ x)
summary(model_h)
```

```{r}
plot(x, y)
abline(-1, 0.5, col="blue", lwd=2)
abline(model_h, col="red", lwd=2)
legend(-2.5, 0.9, legend=c("population", "fitted model"),  col=c("blue","red"), lwd=2)
```

## 13i
```{r}
x <- rnorm(100, mean=0, sd=1)
eps <- rnorm(100, mean=0, sd=0.5)
y <- -1 + 0.5*x + eps
model_i <- lm(y ~ x)
summary(model_i)
```

```{r}
plot(x, y)
abline(-1, 0.5, col="blue", lwd=2)
abline(model_i, col="red", lwd=2)
legend(-2.5, 0.85, legend=c("population", "fitted model"),  col=c("blue","red"), lwd=2)
```

